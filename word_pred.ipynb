{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c63a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = \"\"\"A Game Of Thrones \n",
    "Book One of A Song of Ice and Fire \n",
    "By George R. R. Martin \n",
    "PROLOGUE \n",
    "\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \n",
    "dead.\" \n",
    "\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \n",
    "Gared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \n",
    "\"Dead is dead,\" he said. \"We have no business with the dead.\" \n",
    "\"Are they dead?\" Royce asked softly. \"What proof have we?\" \n",
    "\"Will saw them,\" Gared said. \"If he says they are dead, that's proof enough for me.\" \n",
    "Will had known they would drag him into the quarrel sooner or later. He wished it had been later rather \n",
    "than sooner. \"My mother told me that dead men sing no songs,\" he put in. \n",
    "\"My wet nurse said the same thing, Will,\" Royce replied. \"Never believe anything you hear at a woman's \n",
    "tit. There are things to be learned even from the dead.\" His voice echoed, too loud in the twilit forest. \n",
    "Page 1\n",
    "\n",
    "\"We have a long ride before us,\" Gared pointed out. \"Eight days, maybe nine. And night is falling.\" \n",
    "Ser Waymar Royce glanced at the sky with disinterest. \"It does that every day about this time. Are you \n",
    "unmanned by the dark, Gared?\" \n",
    "Will could see the tightness around Gared's mouth, the barely sup \n",
    "pressed anger in his eyes under the thick black hood of his cloak. Gared had spent forty years in the \n",
    "Night's Watch, man and boy, and he was not accustomed to being made light of. Yet it was more than \n",
    "that. Under the wounded pride, Will could sense something else in the older man. You could taste it; a \n",
    "nervous tension that came perilous close to fear. \n",
    "Will shared his unease. He had been four years on the Wall. The first time he had been sent beyond, all \n",
    "the old stories had come rushing back, and his bowels had turned to water. He had laughed about it \n",
    "afterward. He was a veteran of a hundred rangings by now, and the endless dark wilderness that the \n",
    "southron called the haunted forest had no more terrors for him. \n",
    "Until tonight. Something was different tonight. There was an edge to this darkness that made his hackles \n",
    "rise. Nine days they had been riding, north and northwest and then north again, farther and farther from \n",
    "the Wall, hard on the track of a band of wildling raiders. Each day had been worse than the day that had \n",
    "come before it. Today was the worst of all. A cold wind was blowing out of the north, and it made the \n",
    "trees rustle like living things. All day, Will had felt as though something were watching him, something \n",
    "cold and implacable that loved him not. Gared had felt it too. Will wanted nothing so much as to ride \n",
    "hellbent for the safety of the Wall, but that was not a feeling to share with your commander. \n",
    "Especially not a commander like this one. \n",
    "Ser Waymar Royce was the youngest son of an ancient house with too many heirs. He was a handsome \n",
    "youth of eighteen, grey-eyed and graceful and slender as a knife. Mounted on his huge black destrier, the \n",
    "knight towered above Will and Gared on their smaller garrons. He wore black leather boots, black \n",
    "woolen pants, black moleskin gloves, and a fine supple coat of gleaming black ringmail over layers of \n",
    "black wool and boiled leather. Ser Waymar had been a Sworn Brother of the Night's Watch for less than \n",
    "half a year, but no one could say he had not prepared for his vocation. At least insofar as his wardrobe \n",
    "was concerned. \n",
    "His cloak was his crowning glory; sable, thick and black and soft as sin. \"Bet he killed them all himself, \n",
    "he did,\" Gared told the barracks over wine, \"twisted their little heads off, our mighty warrior.\" They had \n",
    "all shared the laugh. \n",
    "It is hard to take orders from a man you laughed at in your cups, Will reflected as he sat shivering atop \n",
    "his garron. Gared must have felt the same. \n",
    "\"Mormont said as we should track them, and we did,\" Gared said. \n",
    "\"They're dead. They shan't trouble us no more. There's hard riding before us. I don't like this weather. If \n",
    "it snows, we could be a fortnight getting back, and snow's the best we can hope for. Ever seen an ice \n",
    "storm, my lord?\" \n",
    "The lordling seemed not to hear him. He studied the deepening twilight in that half-bored, half-distracted \n",
    "Page 2\n",
    "\n",
    "way he had. Will had ridden with the knight long enough to understand that it was best not to interrupt \n",
    "him when he looked like that. \"Tell me again what you saw, Will. All the details. Leave nothing out.\" \n",
    "Will had been a hunter before he joined the Night's Watch. Well, a poacher in truth. Mallister freeriders \n",
    "had caught him red-handed in the Mallisters' own woods, skinning one of the Mallisters' own bucks, and \n",
    "it had been a choice of putting on the black or losing a hand. No one could move through the woods as \n",
    "silent as Will, and it had not taken the black brothers long to discover his talent. \n",
    "\"The camp is two miles farther on, over that ridge, hard beside a stream,\" Will said. \"I got close as I \n",
    "dared. There's eight of them, men and women both. No children I could see. They put up a lean-to \n",
    "against the rock. The snow's pretty well covered it now, but I could still make it out. No fire burning, but \n",
    "the firepit was still plain as day. No one moving. I watched a long time. No living man ever lay so still.\" \n",
    "\"Did you see any blood?\" \n",
    "\"Well, no,\" Will admitted. \n",
    "\"Did you see any weapons?\" \n",
    "\"Some swords, a few bows. One man had an axe. Heavy-looking, double-bladed, a cruel piece of iron. \n",
    "It was on the ground beside him, right by his hand.\" \n",
    "\"Did you make note of the position of the bodies?\" \n",
    "Will shrugged. \"A couple are sitting up against the rock. Most of them on the ground. Fallen, like.\" \n",
    "\"Or sleeping,\" Royce suggested. \n",
    "\"Fallen,\" Will insisted. \"There's one woman up an ironwood, halfhid in the branches. A far-eyes.\" He \n",
    "smiled thinly. \"I took care she never saw me. When I got closer, I saw that she wasn't moving neither.\" \n",
    "Despite himself, he shivered. \n",
    "\"You have a chill?\" Royce asked. \n",
    "\"Some,\" Will muttered. \"The wind, m'lord.\" \n",
    "The young knight turned back to his grizzled man-at-arms. Frostfallen leaves whispered past them, and \n",
    "Royce's destrier moved restlessly. \"What do you think might have killed these men, Gared?\" Ser \n",
    "Waymar asked casually. He adjusted the drape of his long sable cloak. \n",
    "\"It was the cold,\" Gared said with iron certainty. \"I saw men freeze \n",
    "last winter, and the one before, when I was half a boy. Everyone talks about snows forty foot deep, and \n",
    "how the ice wind comes howling out of the north, but the real enemy is the cold. It steals up on you \n",
    "quieter than Will, and at first you shiver and your teeth chatter and you stamp your feet and dream of \n",
    "mulled wine and nice hot fires. It burns, it does. Nothing burns like the cold. But only for a while. Then it \n",
    "gets inside you and starts to fill you up, and after a while you don't have the strength to fight it. It's easier \n",
    "just to sit down or go to sleep. They say you don't feel any pain toward the end. First you go weak and \n",
    "drowsy, and everything starts to fade, and then it's like sinking into a sea of warm milk. Peaceful, like.\" \n",
    "\"Such eloquence, Gared,\" Ser Waymar observed. \"I never suspected you had it in you.\" \n",
    "Page 3\n",
    "\n",
    "\"I've had the cold in me too, lordling.\" Gared pulled back his hood, giving Ser Waymar a good long look \n",
    "at the stumps where his ears had been. \"Two ears, three toes, and the little finger off my left hand. I got \n",
    "off light. We found my brother frozen at his watch, with a smile on his face.\" \n",
    "Ser Waymar shrugged. \"You ought dress more warmly, Gared.\" \n",
    "Gared glared at the lordling, the scars around his ear holes flushed red with anger where Maester \n",
    "Aemon had cut the ears away. \"We'll see how warm you can dress when the winter comes.\" He pulled \n",
    "up his hood and hunched over his garron, silent and sullen. \n",
    "\"If Gared said it was the cold . . .\" Will began. \n",
    "\"Have you drawn any watches this past week, Will?\" \n",
    "\"Yes, m'lord.\" There never was a week when he did not draw a dozen bloody watches. What was the \n",
    "man driving at? \n",
    "\"And how did you find the Wall?\" \n",
    "\"Weeping,\" Will said, frowning. He saw it clear enough, now that the lordling had pointed it out. \"They \n",
    "couldn't have froze. Not if the Wall was weeping. It wasn't cold enough.\" \n",
    "Royce nodded. \"Bright lad. We've had a few light frosts this past week, and a quick flurry of snow now \n",
    "and then, but surely no cold fierce enough to kill eight grown men. Men clad in fur and leather, let me \n",
    "remind you, with shelter near at hand, and the means of making fire.\" The knight's smile was cocksure. \n",
    "\"Will, lead us there. I would see these dead men for myself.\" \n",
    "And then there was nothing to be done for it. The order had been given, and honor bound them to obey. \n",
    "Will went in front, his shaggy little garron picking the way carefully through the undergrowth. A light \n",
    "snow had fallen the night before, and there were stones and roots and hidden sinks lying just under its \n",
    "crust, waiting for the careless and the unwary. Ser Waymar Royce came next, his great black destrier \n",
    "snorting impatiently. The warhorse was the wrong mount for ranging, but try and tell that to the lordling. \n",
    "Gared brought up the rear. The old man-at-arms muttered to himself as he rode. \n",
    "Twilight deepened. The cloudless sky turned a deep purple, the color of an old bruise, then faded to \n",
    "black. The stars began to come out. A half-moon rose. Will was grateful for the light. \n",
    "\"We can make a better pace than this, surely,\" Royce said when the moon was full risen. \n",
    "\"Not with this horse,\" Will said. Fear had made him insolent. \"Perhaps my lord would care to take the \n",
    "lead?\" \n",
    "Ser Waymar Royce did not deign to reply. \n",
    "Somewhere off in the wood a wolf howled. \n",
    "Will pulled his garron over beneath an ancient gnarled ironwood and dismounted. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23d7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b084b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aeed639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all words are assigned a token number\n",
    "tokenizer.fit_on_texts([faqs]) #multiple texts can be sent so a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7fad06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'had': 4,\n",
       " 'of': 5,\n",
       " 'to': 6,\n",
       " 'he': 7,\n",
       " 'will': 8,\n",
       " 'it': 9,\n",
       " 'was': 10,\n",
       " 'you': 11,\n",
       " 'his': 12,\n",
       " 'gared': 13,\n",
       " 'that': 14,\n",
       " 'in': 15,\n",
       " 'i': 16,\n",
       " 'as': 17,\n",
       " 'not': 18,\n",
       " 'no': 19,\n",
       " 'for': 20,\n",
       " 'at': 21,\n",
       " 'black': 22,\n",
       " 'dead': 23,\n",
       " 'royce': 24,\n",
       " 'with': 25,\n",
       " 'said': 26,\n",
       " 'we': 27,\n",
       " 'ser': 28,\n",
       " 'waymar': 29,\n",
       " 'been': 30,\n",
       " 'on': 31,\n",
       " 'one': 32,\n",
       " 'did': 33,\n",
       " 'man': 34,\n",
       " 'have': 35,\n",
       " 'they': 36,\n",
       " 'him': 37,\n",
       " 'cold': 38,\n",
       " 'them': 39,\n",
       " 'an': 40,\n",
       " 'this': 41,\n",
       " 'could': 42,\n",
       " 'like': 43,\n",
       " 'but': 44,\n",
       " 'men': 45,\n",
       " 'out': 46,\n",
       " 'up': 47,\n",
       " 'are': 48,\n",
       " 'saw': 49,\n",
       " 'me': 50,\n",
       " 'than': 51,\n",
       " 'my': 52,\n",
       " 'there': 53,\n",
       " 'long': 54,\n",
       " 'before': 55,\n",
       " 'see': 56,\n",
       " 'all': 57,\n",
       " 'then': 58,\n",
       " 'when': 59,\n",
       " 'back': 60,\n",
       " 'is': 61,\n",
       " 'enough': 62,\n",
       " 'day': 63,\n",
       " 'light': 64,\n",
       " 'wall': 65,\n",
       " 'over': 66,\n",
       " 'half': 67,\n",
       " 'lordling': 68,\n",
       " 'by': 69,\n",
       " 'asked': 70,\n",
       " 'old': 71,\n",
       " 'past': 72,\n",
       " 'come': 73,\n",
       " 'what': 74,\n",
       " 'if': 75,\n",
       " 'or': 76,\n",
       " 'never': 77,\n",
       " 'too': 78,\n",
       " 'us': 79,\n",
       " 'watch': 80,\n",
       " 'made': 81,\n",
       " 'more': 82,\n",
       " 'something': 83,\n",
       " 'now': 84,\n",
       " 'north': 85,\n",
       " 'hard': 86,\n",
       " 'nothing': 87,\n",
       " 'your': 88,\n",
       " 'off': 89,\n",
       " 'garron': 90,\n",
       " 'hand': 91,\n",
       " 'any': 92,\n",
       " 'ice': 93,\n",
       " 'fire': 94,\n",
       " 'woods': 95,\n",
       " 'began': 96,\n",
       " 'dark': 97,\n",
       " 'around': 98,\n",
       " 'just': 99,\n",
       " 'smile': 100,\n",
       " 'go': 101,\n",
       " 'would': 102,\n",
       " 'be': 103,\n",
       " 'from': 104,\n",
       " 'page': 105,\n",
       " 'eight': 106,\n",
       " 'about': 107,\n",
       " 'time': 108,\n",
       " 'under': 109,\n",
       " 'hood': 110,\n",
       " 'cloak': 111,\n",
       " \"night's\": 112,\n",
       " 'first': 113,\n",
       " 'turned': 114,\n",
       " 'farther': 115,\n",
       " 'wind': 116,\n",
       " 'felt': 117,\n",
       " 'destrier': 118,\n",
       " 'knight': 119,\n",
       " 'leather': 120,\n",
       " 'himself': 121,\n",
       " 'little': 122,\n",
       " \"there's\": 123,\n",
       " \"don't\": 124,\n",
       " 'can': 125,\n",
       " 'well': 126,\n",
       " 'got': 127,\n",
       " 'still': 128,\n",
       " 'make': 129,\n",
       " 'fallen': 130,\n",
       " 'how': 131,\n",
       " 'pulled': 132,\n",
       " 'ears': 133,\n",
       " 'week': 134,\n",
       " 'r': 135,\n",
       " 'should': 136,\n",
       " 'do': 137,\n",
       " 'rise': 138,\n",
       " 'seen': 139,\n",
       " 'proof': 140,\n",
       " 'into': 141,\n",
       " 'sooner': 142,\n",
       " 'later': 143,\n",
       " 'told': 144,\n",
       " 'put': 145,\n",
       " 'same': 146,\n",
       " 'hear': 147,\n",
       " 'things': 148,\n",
       " 'forest': 149,\n",
       " 'ride': 150,\n",
       " 'pointed': 151,\n",
       " 'days': 152,\n",
       " 'nine': 153,\n",
       " 'night': 154,\n",
       " 'sky': 155,\n",
       " 'does': 156,\n",
       " 'anger': 157,\n",
       " 'eyes': 158,\n",
       " 'thick': 159,\n",
       " 'forty': 160,\n",
       " 'years': 161,\n",
       " 'boy': 162,\n",
       " 'came': 163,\n",
       " 'close': 164,\n",
       " 'fear': 165,\n",
       " 'shared': 166,\n",
       " 'laughed': 167,\n",
       " 'tonight': 168,\n",
       " 'riding': 169,\n",
       " 'again': 170,\n",
       " 'track': 171,\n",
       " 'living': 172,\n",
       " 'were': 173,\n",
       " 'so': 174,\n",
       " 'commander': 175,\n",
       " 'ancient': 176,\n",
       " 'their': 177,\n",
       " 'brother': 178,\n",
       " 'say': 179,\n",
       " 'sable': 180,\n",
       " 'killed': 181,\n",
       " 'wine': 182,\n",
       " 'take': 183,\n",
       " 'snows': 184,\n",
       " \"snow's\": 185,\n",
       " 'best': 186,\n",
       " 'ever': 187,\n",
       " 'lord': 188,\n",
       " 'twilight': 189,\n",
       " 'way': 190,\n",
       " 'tell': 191,\n",
       " 'red': 192,\n",
       " \"mallisters'\": 193,\n",
       " 'own': 194,\n",
       " 'through': 195,\n",
       " 'silent': 196,\n",
       " 'two': 197,\n",
       " 'beside': 198,\n",
       " 'against': 199,\n",
       " 'rock': 200,\n",
       " 'moving': 201,\n",
       " 'some': 202,\n",
       " 'few': 203,\n",
       " 'iron': 204,\n",
       " 'ground': 205,\n",
       " 'shrugged': 206,\n",
       " 'ironwood': 207,\n",
       " 'care': 208,\n",
       " 'she': 209,\n",
       " \"wasn't\": 210,\n",
       " 'muttered': 211,\n",
       " \"m'lord\": 212,\n",
       " 'arms': 213,\n",
       " 'these': 214,\n",
       " 'winter': 215,\n",
       " 'deep': 216,\n",
       " 'comes': 217,\n",
       " 'burns': 218,\n",
       " 'while': 219,\n",
       " 'starts': 220,\n",
       " \"it's\": 221,\n",
       " 'warm': 222,\n",
       " 'where': 223,\n",
       " 'dress': 224,\n",
       " 'watches': 225,\n",
       " 'weeping': 226,\n",
       " 'snow': 227,\n",
       " 'surely': 228,\n",
       " 'lead': 229,\n",
       " 'moon': 230,\n",
       " 'game': 231,\n",
       " 'thrones': 232,\n",
       " 'book': 233,\n",
       " 'song': 234,\n",
       " 'george': 235,\n",
       " 'martin': 236,\n",
       " 'prologue': 237,\n",
       " 'start': 238,\n",
       " 'urged': 239,\n",
       " 'grow': 240,\n",
       " 'wildlings': 241,\n",
       " 'frighten': 242,\n",
       " 'hint': 243,\n",
       " 'bait': 244,\n",
       " 'fifty': 245,\n",
       " 'lordlings': 246,\n",
       " 'business': 247,\n",
       " 'softly': 248,\n",
       " 'says': 249,\n",
       " \"that's\": 250,\n",
       " 'known': 251,\n",
       " 'drag': 252,\n",
       " 'quarrel': 253,\n",
       " 'wished': 254,\n",
       " 'rather': 255,\n",
       " 'mother': 256,\n",
       " 'sing': 257,\n",
       " 'songs': 258,\n",
       " 'wet': 259,\n",
       " 'nurse': 260,\n",
       " 'thing': 261,\n",
       " 'replied': 262,\n",
       " 'believe': 263,\n",
       " 'anything': 264,\n",
       " \"woman's\": 265,\n",
       " 'tit': 266,\n",
       " 'learned': 267,\n",
       " 'even': 268,\n",
       " 'voice': 269,\n",
       " 'echoed': 270,\n",
       " 'loud': 271,\n",
       " 'twilit': 272,\n",
       " '1': 273,\n",
       " 'maybe': 274,\n",
       " 'falling': 275,\n",
       " 'glanced': 276,\n",
       " 'disinterest': 277,\n",
       " 'every': 278,\n",
       " 'unmanned': 279,\n",
       " 'tightness': 280,\n",
       " \"gared's\": 281,\n",
       " 'mouth': 282,\n",
       " 'barely': 283,\n",
       " 'sup': 284,\n",
       " 'pressed': 285,\n",
       " 'spent': 286,\n",
       " 'accustomed': 287,\n",
       " 'being': 288,\n",
       " 'yet': 289,\n",
       " 'wounded': 290,\n",
       " 'pride': 291,\n",
       " 'sense': 292,\n",
       " 'else': 293,\n",
       " 'older': 294,\n",
       " 'taste': 295,\n",
       " 'nervous': 296,\n",
       " 'tension': 297,\n",
       " 'perilous': 298,\n",
       " 'unease': 299,\n",
       " 'four': 300,\n",
       " 'sent': 301,\n",
       " 'beyond': 302,\n",
       " 'stories': 303,\n",
       " 'rushing': 304,\n",
       " 'bowels': 305,\n",
       " 'water': 306,\n",
       " 'afterward': 307,\n",
       " 'veteran': 308,\n",
       " 'hundred': 309,\n",
       " 'rangings': 310,\n",
       " 'endless': 311,\n",
       " 'wilderness': 312,\n",
       " 'southron': 313,\n",
       " 'called': 314,\n",
       " 'haunted': 315,\n",
       " 'terrors': 316,\n",
       " 'until': 317,\n",
       " 'different': 318,\n",
       " 'edge': 319,\n",
       " 'darkness': 320,\n",
       " 'hackles': 321,\n",
       " 'northwest': 322,\n",
       " 'band': 323,\n",
       " 'wildling': 324,\n",
       " 'raiders': 325,\n",
       " 'each': 326,\n",
       " 'worse': 327,\n",
       " 'today': 328,\n",
       " 'worst': 329,\n",
       " 'blowing': 330,\n",
       " 'trees': 331,\n",
       " 'rustle': 332,\n",
       " 'though': 333,\n",
       " 'watching': 334,\n",
       " 'implacable': 335,\n",
       " 'loved': 336,\n",
       " 'wanted': 337,\n",
       " 'much': 338,\n",
       " 'hellbent': 339,\n",
       " 'safety': 340,\n",
       " 'feeling': 341,\n",
       " 'share': 342,\n",
       " 'especially': 343,\n",
       " 'youngest': 344,\n",
       " 'son': 345,\n",
       " 'house': 346,\n",
       " 'many': 347,\n",
       " 'heirs': 348,\n",
       " 'handsome': 349,\n",
       " 'youth': 350,\n",
       " 'eighteen': 351,\n",
       " 'grey': 352,\n",
       " 'eyed': 353,\n",
       " 'graceful': 354,\n",
       " 'slender': 355,\n",
       " 'knife': 356,\n",
       " 'mounted': 357,\n",
       " 'huge': 358,\n",
       " 'towered': 359,\n",
       " 'above': 360,\n",
       " 'smaller': 361,\n",
       " 'garrons': 362,\n",
       " 'wore': 363,\n",
       " 'boots': 364,\n",
       " 'woolen': 365,\n",
       " 'pants': 366,\n",
       " 'moleskin': 367,\n",
       " 'gloves': 368,\n",
       " 'fine': 369,\n",
       " 'supple': 370,\n",
       " 'coat': 371,\n",
       " 'gleaming': 372,\n",
       " 'ringmail': 373,\n",
       " 'layers': 374,\n",
       " 'wool': 375,\n",
       " 'boiled': 376,\n",
       " 'sworn': 377,\n",
       " 'less': 378,\n",
       " 'year': 379,\n",
       " 'prepared': 380,\n",
       " 'vocation': 381,\n",
       " 'least': 382,\n",
       " 'insofar': 383,\n",
       " 'wardrobe': 384,\n",
       " 'concerned': 385,\n",
       " 'crowning': 386,\n",
       " 'glory': 387,\n",
       " 'soft': 388,\n",
       " 'sin': 389,\n",
       " 'bet': 390,\n",
       " 'barracks': 391,\n",
       " 'twisted': 392,\n",
       " 'heads': 393,\n",
       " 'our': 394,\n",
       " 'mighty': 395,\n",
       " 'warrior': 396,\n",
       " 'laugh': 397,\n",
       " 'orders': 398,\n",
       " 'cups': 399,\n",
       " 'reflected': 400,\n",
       " 'sat': 401,\n",
       " 'shivering': 402,\n",
       " 'atop': 403,\n",
       " 'must': 404,\n",
       " 'mormont': 405,\n",
       " \"they're\": 406,\n",
       " \"shan't\": 407,\n",
       " 'trouble': 408,\n",
       " 'weather': 409,\n",
       " 'fortnight': 410,\n",
       " 'getting': 411,\n",
       " 'hope': 412,\n",
       " 'storm': 413,\n",
       " 'seemed': 414,\n",
       " 'studied': 415,\n",
       " 'deepening': 416,\n",
       " 'bored': 417,\n",
       " 'distracted': 418,\n",
       " '2': 419,\n",
       " 'ridden': 420,\n",
       " 'understand': 421,\n",
       " 'interrupt': 422,\n",
       " 'looked': 423,\n",
       " 'details': 424,\n",
       " 'leave': 425,\n",
       " 'hunter': 426,\n",
       " 'joined': 427,\n",
       " 'poacher': 428,\n",
       " 'truth': 429,\n",
       " 'mallister': 430,\n",
       " 'freeriders': 431,\n",
       " 'caught': 432,\n",
       " 'handed': 433,\n",
       " 'skinning': 434,\n",
       " 'bucks': 435,\n",
       " 'choice': 436,\n",
       " 'putting': 437,\n",
       " 'losing': 438,\n",
       " 'move': 439,\n",
       " 'taken': 440,\n",
       " 'brothers': 441,\n",
       " 'discover': 442,\n",
       " 'talent': 443,\n",
       " 'camp': 444,\n",
       " 'miles': 445,\n",
       " 'ridge': 446,\n",
       " 'stream': 447,\n",
       " 'dared': 448,\n",
       " 'women': 449,\n",
       " 'both': 450,\n",
       " 'children': 451,\n",
       " 'lean': 452,\n",
       " 'pretty': 453,\n",
       " 'covered': 454,\n",
       " 'burning': 455,\n",
       " 'firepit': 456,\n",
       " 'plain': 457,\n",
       " 'watched': 458,\n",
       " 'lay': 459,\n",
       " 'blood': 460,\n",
       " 'admitted': 461,\n",
       " 'weapons': 462,\n",
       " 'swords': 463,\n",
       " 'bows': 464,\n",
       " 'axe': 465,\n",
       " 'heavy': 466,\n",
       " 'looking': 467,\n",
       " 'double': 468,\n",
       " 'bladed': 469,\n",
       " 'cruel': 470,\n",
       " 'piece': 471,\n",
       " 'right': 472,\n",
       " 'note': 473,\n",
       " 'position': 474,\n",
       " 'bodies': 475,\n",
       " 'couple': 476,\n",
       " 'sitting': 477,\n",
       " 'most': 478,\n",
       " 'sleeping': 479,\n",
       " 'suggested': 480,\n",
       " 'insisted': 481,\n",
       " 'woman': 482,\n",
       " 'halfhid': 483,\n",
       " 'branches': 484,\n",
       " 'far': 485,\n",
       " 'smiled': 486,\n",
       " 'thinly': 487,\n",
       " 'took': 488,\n",
       " 'closer': 489,\n",
       " 'neither': 490,\n",
       " 'despite': 491,\n",
       " 'shivered': 492,\n",
       " 'chill': 493,\n",
       " 'young': 494,\n",
       " 'grizzled': 495,\n",
       " 'frostfallen': 496,\n",
       " 'leaves': 497,\n",
       " 'whispered': 498,\n",
       " \"royce's\": 499,\n",
       " 'moved': 500,\n",
       " 'restlessly': 501,\n",
       " 'think': 502,\n",
       " 'might': 503,\n",
       " 'casually': 504,\n",
       " 'adjusted': 505,\n",
       " 'drape': 506,\n",
       " 'certainty': 507,\n",
       " 'freeze': 508,\n",
       " 'last': 509,\n",
       " 'everyone': 510,\n",
       " 'talks': 511,\n",
       " 'foot': 512,\n",
       " 'howling': 513,\n",
       " 'real': 514,\n",
       " 'enemy': 515,\n",
       " 'steals': 516,\n",
       " 'quieter': 517,\n",
       " 'shiver': 518,\n",
       " 'teeth': 519,\n",
       " 'chatter': 520,\n",
       " 'stamp': 521,\n",
       " 'feet': 522,\n",
       " 'dream': 523,\n",
       " 'mulled': 524,\n",
       " 'nice': 525,\n",
       " 'hot': 526,\n",
       " 'fires': 527,\n",
       " 'only': 528,\n",
       " 'gets': 529,\n",
       " 'inside': 530,\n",
       " 'fill': 531,\n",
       " 'after': 532,\n",
       " 'strength': 533,\n",
       " 'fight': 534,\n",
       " 'easier': 535,\n",
       " 'sit': 536,\n",
       " 'down': 537,\n",
       " 'sleep': 538,\n",
       " 'feel': 539,\n",
       " 'pain': 540,\n",
       " 'toward': 541,\n",
       " 'end': 542,\n",
       " 'weak': 543,\n",
       " 'drowsy': 544,\n",
       " 'everything': 545,\n",
       " 'fade': 546,\n",
       " 'sinking': 547,\n",
       " 'sea': 548,\n",
       " 'milk': 549,\n",
       " 'peaceful': 550,\n",
       " 'such': 551,\n",
       " 'eloquence': 552,\n",
       " 'observed': 553,\n",
       " 'suspected': 554,\n",
       " '3': 555,\n",
       " \"i've\": 556,\n",
       " 'giving': 557,\n",
       " 'good': 558,\n",
       " 'look': 559,\n",
       " 'stumps': 560,\n",
       " 'three': 561,\n",
       " 'toes': 562,\n",
       " 'finger': 563,\n",
       " 'left': 564,\n",
       " 'found': 565,\n",
       " 'frozen': 566,\n",
       " 'face': 567,\n",
       " 'ought': 568,\n",
       " 'warmly': 569,\n",
       " 'glared': 570,\n",
       " 'scars': 571,\n",
       " 'ear': 572,\n",
       " 'holes': 573,\n",
       " 'flushed': 574,\n",
       " 'maester': 575,\n",
       " 'aemon': 576,\n",
       " 'cut': 577,\n",
       " 'away': 578,\n",
       " \"we'll\": 579,\n",
       " 'hunched': 580,\n",
       " 'sullen': 581,\n",
       " 'drawn': 582,\n",
       " 'yes': 583,\n",
       " 'draw': 584,\n",
       " 'dozen': 585,\n",
       " 'bloody': 586,\n",
       " 'driving': 587,\n",
       " 'find': 588,\n",
       " 'frowning': 589,\n",
       " 'clear': 590,\n",
       " \"couldn't\": 591,\n",
       " 'froze': 592,\n",
       " 'nodded': 593,\n",
       " 'bright': 594,\n",
       " 'lad': 595,\n",
       " \"we've\": 596,\n",
       " 'frosts': 597,\n",
       " 'quick': 598,\n",
       " 'flurry': 599,\n",
       " 'fierce': 600,\n",
       " 'kill': 601,\n",
       " 'grown': 602,\n",
       " 'clad': 603,\n",
       " 'fur': 604,\n",
       " 'let': 605,\n",
       " 'remind': 606,\n",
       " 'shelter': 607,\n",
       " 'near': 608,\n",
       " 'means': 609,\n",
       " 'making': 610,\n",
       " \"knight's\": 611,\n",
       " 'cocksure': 612,\n",
       " 'myself': 613,\n",
       " 'done': 614,\n",
       " 'order': 615,\n",
       " 'given': 616,\n",
       " 'honor': 617,\n",
       " 'bound': 618,\n",
       " 'obey': 619,\n",
       " 'went': 620,\n",
       " 'front': 621,\n",
       " 'shaggy': 622,\n",
       " 'picking': 623,\n",
       " 'carefully': 624,\n",
       " 'undergrowth': 625,\n",
       " 'stones': 626,\n",
       " 'roots': 627,\n",
       " 'hidden': 628,\n",
       " 'sinks': 629,\n",
       " 'lying': 630,\n",
       " 'its': 631,\n",
       " 'crust': 632,\n",
       " 'waiting': 633,\n",
       " 'careless': 634,\n",
       " 'unwary': 635,\n",
       " 'next': 636,\n",
       " 'great': 637,\n",
       " 'snorting': 638,\n",
       " 'impatiently': 639,\n",
       " 'warhorse': 640,\n",
       " 'wrong': 641,\n",
       " 'mount': 642,\n",
       " 'ranging': 643,\n",
       " 'try': 644,\n",
       " 'brought': 645,\n",
       " 'rear': 646,\n",
       " 'rode': 647,\n",
       " 'deepened': 648,\n",
       " 'cloudless': 649,\n",
       " 'purple': 650,\n",
       " 'color': 651,\n",
       " 'bruise': 652,\n",
       " 'faded': 653,\n",
       " 'stars': 654,\n",
       " 'rose': 655,\n",
       " 'grateful': 656,\n",
       " 'better': 657,\n",
       " 'pace': 658,\n",
       " 'full': 659,\n",
       " 'risen': 660,\n",
       " 'horse': 661,\n",
       " 'insolent': 662,\n",
       " 'perhaps': 663,\n",
       " 'deign': 664,\n",
       " 'reply': 665,\n",
       " 'somewhere': 666,\n",
       " 'wood': 667,\n",
       " 'wolf': 668,\n",
       " 'howled': 669,\n",
       " 'beneath': 670,\n",
       " 'gnarled': 671,\n",
       " 'dismounted': 672}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0449f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all the sentences in our data\n",
    "#we'll split the faq on \\n basis\n",
    "#we will convert the sentences to series of tokens bassed on the tokens made earlier\n",
    "#the [0] is added so that we get the list of the output and not list of list   \n",
    "\n",
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0] \n",
    "\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a56c0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero padding to keep size of list same\n",
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fc5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c70ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_sequences =pad_sequences(input_sequences, maxlen= max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cff6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data , for each sentence we need last as expected output so this will say all till last word for every sentence\n",
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029f8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every sequence last word is extracted\n",
    "y= padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bd7eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4f14758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b45207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one haut encoding \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes = 673) #len of tokenizer.word_index +1 to cover last word\n",
    "# one haut encoding starts from 0 and wordindex starts from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a299230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677, 673)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb90cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6def946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a896a6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73291c",
   "metadata": {},
   "source": [
    "for gpu training use CuDNNLSTM instead of LSTM. it is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66331c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ac8d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(673,100,input_length=22))\n",
    "\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(673,activation='softmax')) #283 coz no of words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "461013f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "720c321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 22, 100)           67300     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 673)               101623    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 319,523\n",
      "Trainable params: 319,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f59d16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 5s 8ms/step - loss: 6.2253 - accuracy: 0.0501\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.8161 - accuracy: 0.0584\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.7370 - accuracy: 0.0584\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.6541 - accuracy: 0.0584\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.5667 - accuracy: 0.0584\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.4651 - accuracy: 0.0578\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.3451 - accuracy: 0.0650\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.2110 - accuracy: 0.0769\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 5.0570 - accuracy: 0.0888\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.8900 - accuracy: 0.0972\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.7125 - accuracy: 0.1133\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.5279 - accuracy: 0.1276\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 4.3500 - accuracy: 0.1371\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 4.1676 - accuracy: 0.1527\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.9905 - accuracy: 0.1729\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.8175 - accuracy: 0.2039\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.6336 - accuracy: 0.2338\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.4564 - accuracy: 0.2618\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.2711 - accuracy: 0.3119\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 3.0921 - accuracy: 0.3548\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.9187 - accuracy: 0.4091\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.7505 - accuracy: 0.4502\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.5774 - accuracy: 0.5128\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.4144 - accuracy: 0.5492\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.2643 - accuracy: 0.5874\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.1122 - accuracy: 0.6219\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.9645 - accuracy: 0.6661\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.8319 - accuracy: 0.6965\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.6966 - accuracy: 0.7275\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.5787 - accuracy: 0.7591\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.4642 - accuracy: 0.7859\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.3612 - accuracy: 0.8044\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.2626 - accuracy: 0.8265\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.1680 - accuracy: 0.8497\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.0848 - accuracy: 0.8652\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.0079 - accuracy: 0.8712\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.9333 - accuracy: 0.8897\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.8661 - accuracy: 0.9022\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.8075 - accuracy: 0.9046\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.7506 - accuracy: 0.9165\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.9314\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6504 - accuracy: 0.9374\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.9439\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.9505\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.9547\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.9595\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.9595\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.9624\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.9642\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.9690\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.9708\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3298 - accuracy: 0.9684\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3112 - accuracy: 0.9744\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2924 - accuracy: 0.9738\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2758 - accuracy: 0.9744\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2625 - accuracy: 0.9750\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2470 - accuracy: 0.9750\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2344 - accuracy: 0.9756\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2222 - accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2103 - accuracy: 0.9761\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2002 - accuracy: 0.9756\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9767\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9756\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1757 - accuracy: 0.9761\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9773\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9756\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9779\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1474 - accuracy: 0.9767\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.9756\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9756\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9791\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9761\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1237 - accuracy: 0.9761\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9761\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9767\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9756\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9773\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9744\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9773\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9767\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9756\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9773\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9750\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9756\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9750\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9756\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9738\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9767\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9761\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9744\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9767\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9750\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9761\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9750\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9756\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9756\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9785\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9738\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9744\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19dedeed5e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9904f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 215ms/step\n",
      "ser\n"
     ]
    }
   ],
   "source": [
    "#to predict our trained models output\n",
    "#tokennise\n",
    "#padding\n",
    "#predict\n",
    "\n",
    "text = 'Do the dead frighten you?'\n",
    "\n",
    "#tokenise\n",
    "tokened_text =  tokenizer.texts_to_sequences([text])[0]\n",
    "#padd\n",
    "padded_token_input = pad_sequences([tokened_text],maxlen=22,padding='pre')\n",
    "#predict\n",
    "position = np.argmax(model.predict(padded_token_input)) \n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index == position:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49de0205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "329ac926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_index #this is to find the number of the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc68bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66621e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Do the dead frighten you? ser\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Do the dead frighten you? ser waymar\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Do the dead frighten you? ser waymar royce\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Do the dead frighten you? ser waymar royce asked\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Do the dead frighten you? ser waymar royce asked with\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Do the dead frighten you? ser waymar royce asked with just\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Do the dead frighten you? ser waymar royce asked with just the\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Do the dead frighten you? ser waymar royce asked with just the hint\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Do the dead frighten you? ser waymar royce asked with just the hint of\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Do the dead frighten you? ser waymar royce asked with just the hint of a\n"
     ]
    }
   ],
   "source": [
    "# to predict 5 words\n",
    "text = \"Do the dead frighten you?\"\n",
    "\n",
    "for i in range(10):\n",
    "    #tokenise\n",
    "    token_text =  tokenizer.texts_to_sequences([text])[0]\n",
    "    #padd\n",
    "    padded_token_text = pad_sequences([token_text],maxlen=56,padding='pre')\n",
    "    #predict\n",
    "    position = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == position:\n",
    "            text = text + \" \"+ word\n",
    "            print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183846a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
